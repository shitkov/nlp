{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt --trusted-host pypi.org --trusted-host files.pythonhosted.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "c46xchGszzKx"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7uRg-Hw_0AnA"
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('./data/h2i_01_asset_type_train.csv')\n",
    "data_valid = pd.read_csv('./data/h2i_01_asset_type_valid.csv')\n",
    "data_test = pd.read_csv('./data/h2i_01_asset_type_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nI7gYjj9GzkF"
   },
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer()\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "tokenizer.enable_padding(pad_id=0, pad_token='<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nNok-OoyHGJ0"
   },
   "outputs": [],
   "source": [
    "texts = [text.lower() for text in list(data_train['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cyvdv0B0HRPe"
   },
   "outputs": [],
   "source": [
    "with open('texts.txt', 'w') as f:\n",
    "    for text in texts:\n",
    "        f.write(\"%s\\n\" % text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EIbPPIm0G3vX"
   },
   "outputs": [],
   "source": [
    "tokenizer.train(\n",
    "    files=['texts.txt'],\n",
    "    vocab_size=3_000,\n",
    "    min_frequency=2,\n",
    "    special_tokens=['<pad>', '<unk>']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kavnGbD3It0u"
   },
   "outputs": [],
   "source": [
    "tokenizer.save('tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3pefFn_yHEE3"
   },
   "outputs": [],
   "source": [
    "tokens_list = [tokenizer.encode(text).ids for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "i7b-XPBfHyK9"
   },
   "outputs": [],
   "source": [
    "data_train['tokens'] = tokens_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NCF_SCwnH2AJ"
   },
   "outputs": [],
   "source": [
    "len_list = [len(tokens) for tokens in list(data_train['tokens'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XtCnauIZH4rF"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(len_list, density=True, bins=50)\n",
    "plt.ylabel('part')\n",
    "plt.xlabel('tokens in sentence');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8qydCYr0H9Ou"
   },
   "outputs": [],
   "source": [
    "max_len = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, tokens, labels, max_len):\n",
    "        self.tokens = tokens\n",
    "        self.labels = labels\n",
    "        self.max_len = max_len\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        label = torch.tensor(label)\n",
    "        tokens = self.tokens[idx]\n",
    "        out = torch.zeros(self.max_len, dtype=torch.long)\n",
    "        out[:len(tokens)] = torch.tensor(tokens, dtype=torch.long)[:self.max_len]\n",
    "        return out, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "y_train = data_train['label'].values\n",
    "\n",
    "counts = np.bincount(y_train.astype(int))\n",
    "labels_weights = 1. / counts\n",
    "weights = labels_weights[y_train.astype(int)]\n",
    "sampler = WeightedRandomSampler(weights, len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "FNvsf_w2JWIL"
   },
   "outputs": [],
   "source": [
    "labels = list(data_train['label'])\n",
    "train_dataset = CustomDataset(tokens_list, labels, max_len)\n",
    "train_loader = DataLoader(train_dataset, sampler=sampler, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "aYI5E5rnAcW6"
   },
   "outputs": [],
   "source": [
    "valid_texts = [text.lower() for text in list(data_valid['text'])]\n",
    "valid_ids = [tokenizer.encode(text).ids for text in valid_texts]\n",
    "valid_labels = list(data_valid['label'])\n",
    "valid_dataset = CustomDataset(valid_ids, valid_labels, max_len)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "u3lWmCf1RPeF"
   },
   "outputs": [],
   "source": [
    "test_texts = [text.lower() for text in list(data_test['text'])]\n",
    "test_ids = [tokenizer.encode(text).ids for text in test_texts]\n",
    "test_labels = list(data_test['label'])\n",
    "test_dataset = CustomDataset(test_ids, test_labels, max_len)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Q2mrO5n5Q7za"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pytorch-metric-learning --trusted-host pypi.org --trusted-host files.pythonhosted.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning import distances, losses, miners, reducers, testers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class NeuralNetworkML(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, hidden_dim=128, vocab_size=3000, embedding_dim=300, linear_dim=128, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm_layer = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)   \n",
    "        self.fc_layer = nn.Linear(hidden_dim * 2, linear_dim)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        embeddings = self.embedding_layer(inputs)\n",
    "        lstm_out, (ht, ct) = self.lstm_layer(embeddings)\n",
    "        out = ht.transpose(0, 1)\n",
    "        out = out.reshape(batch_size, -1)\n",
    "        out = self.fc_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "G62Tzj1X2uv_"
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetworkML(hidden_dim=256, vocab_size=3000, embedding_dim=300, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = distances.CosineSimilarity()\n",
    "reducer = reducers.ThresholdReducer(low=0)\n",
    "loss_func = losses.TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)\n",
    "mining_func = miners.TripletMarginMiner(\n",
    "    margin=0.2, distance=distance, type_of_triplets=\"semihard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetworkML(\n",
       "  (embedding_layer): Embedding(3000, 300)\n",
       "  (lstm_layer): LSTM(300, 256, batch_first=True, bidirectional=True)\n",
       "  (fc_layer): Linear(in_features=512, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:08<00:00, 16.21it/s]\n",
      "  1%|▏         | 2/136 [00:00<00:09, 14.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.5579, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:08<00:00, 16.26it/s]\n",
      "  1%|▏         | 2/136 [00:00<00:08, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.7702, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:08<00:00, 16.59it/s]\n",
      "  1%|▏         | 2/136 [00:00<00:08, 16.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.4390, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:08<00:00, 16.53it/s]\n",
      "  1%|▏         | 2/136 [00:00<00:08, 15.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.7116, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:08<00:00, 16.92it/s]\n",
      "  1%|▏         | 2/136 [00:00<00:07, 18.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.4307, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:08<00:00, 15.85it/s]\n",
      "  1%|▏         | 2/136 [00:00<00:11, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.9084, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:08<00:00, 15.56it/s]\n",
      "  1%|▏         | 2/136 [00:00<00:07, 17.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.9923, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:08<00:00, 16.58it/s]\n",
      "  1%|▏         | 2/136 [00:00<00:07, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2132, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:08<00:00, 15.50it/s]\n",
      "  1%|▏         | 2/136 [00:00<00:09, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6171, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:09<00:00, 14.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.1715, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "num_epochs = 10\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    sum_loss = 0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        embeddings = model(inputs)\n",
    "        indices_tuple = mining_func(embeddings, labels)\n",
    "        loss = loss_func(embeddings, labels, indices_tuple)\n",
    "        sum_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(sum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtNet(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super().__init__()\n",
    "        self.pretrained = pretrained_model\n",
    "        self.new_layers = nn.Sequential(nn.Linear(128, 64),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Linear(64, 5))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pretrained(x)\n",
    "        x = self.new_layers(x)\n",
    "        x = torch.squeeze(x, 1)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model, optimizer, loss_function, train_loader, valid_loader, test_loader, device, epochs=10):\n",
    "    best_score = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predict = model(inputs)\n",
    "            loss = loss_function(predict, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        _, _, score_valid = eval_nn(model, valid_loader)\n",
    "        _, _, score_test = eval_nn(model, test_loader)\n",
    "        print(epoch, score_valid, score_test)\n",
    "        if score_valid > best_score:\n",
    "            best_score = score_valid\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_nn(model, data_loader):\n",
    "    predicted = []\n",
    "    labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            outputs = model(x)\n",
    "            _, predict = torch.max(outputs.data, 1)\n",
    "            predict = predict.cpu().detach().numpy().tolist()\n",
    "            predicted += predict\n",
    "            labels += y\n",
    "        score = f1_score(labels, predicted, average='macro')\n",
    "    return labels, predicted, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:15<00:00,  8.53it/s]\n",
      "  0%|          | 0/136 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.94919676174815 0.9195454545454546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:17<00:00,  7.57it/s]\n",
      "  1%|          | 1/136 [00:00<00:17,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9519952541032233 0.9224760931454852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:19<00:00,  7.15it/s]\n",
      "  1%|          | 1/136 [00:00<00:16,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.94919676174815 0.9224760931454852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:19<00:00,  6.92it/s]\n",
      "  1%|          | 1/136 [00:00<00:15,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.94919676174815 0.9224760931454852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:21<00:00,  6.30it/s]\n",
      "  1%|          | 1/136 [00:00<00:14,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.94919676174815 0.9224760931454852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:21<00:00,  6.40it/s]\n",
      "  1%|          | 1/136 [00:00<00:20,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.9547958214624882 0.9224760931454852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:22<00:00,  6.07it/s]\n",
      "  0%|          | 0/136 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.94919676174815 0.9252922077922078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:22<00:00,  6.17it/s]\n",
      "  1%|          | 1/136 [00:00<00:26,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.94919676174815 0.9252922077922078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:20<00:00,  6.49it/s]\n",
      "  1%|          | 1/136 [00:00<00:21,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.94919676174815 0.9252922077922078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:20<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.94919676174815 0.9252922077922078\n",
      "0.9547958214624882\n"
     ]
    }
   ],
   "source": [
    "ext_model = ExtNet(model)\n",
    "ext_model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.AdamW(ext_model.parameters())\n",
    "score = train_nn(ext_model, optimizer, loss_function, train_loader, valid_loader, test_loader, device)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP+KcUv4IyZQhT5InbLhHan",
   "collapsed_sections": [],
   "name": "h2i_01_light_models_rnn_fit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
